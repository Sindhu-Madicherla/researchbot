{"docstore/metadata": {"2405.02277": {"doc_hash": "77d3bfa1f156e202e1029e51eeab794f1c4e1e995fee6838bda2e97a9308d0f7"}, "2405.02267": {"doc_hash": "35f0bb02a3fe7f6fcf5755d63e3595261ebc4a9277745639cab970fd8ba9ce3c"}, "2405.02266": {"doc_hash": "714b92fb5bfed82e507e40ec07404ee0289a55a024eb9d0567bd723d0f7826e3"}}, "docstore/data": {"2405.02277": {"__data__": {"id_": "2405.02277", "embedding": null, "metadata": {"title": "An error-mitigated photonic quantum circuit Born machine", "authors": "Alexia Salavrakos, Tigran Sedrakyan, James Mills, Rawad Mezher", "published": "2024-05-03", "filepath": "articles\\2405.02277v1.An_error_mitigated_photonic_quantum_circuit_Born_machine.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "(2 + _\u03f5_ ) _||_ _A_ _||_ 2 _n_ _,_\n\n\n _|_ E ( Per 2 ( _A_ )) _|\u2212|_ Per 2 ( _A_ ) _|_\n\n _\u2264|_ E ( Per 2 ( _A_ )) _\u2212_ Per 2 ( _A_ ) _|_\n\n_|_ Per ( _A_ ) _|_ 2  of the same order of magnitude as that\nobtained from _O_ ( _t_ ) runs of a boson sampler.\nLet _A_ be an _n_ _\u00d7_ _n_ matrix with complex en-\ntries. Gurvits algorithm [ 43 ] provides an esti-\nmate E ( Per ( _A_ )) of Per ( _A_ ), the permanent of _A_ ,\nto within additive precision _\u03f5_ _||_ _A_ _||_ _n_ , where _||_ _A_ _||_ is\nthe spectral norm of _A_ , and _\u03f5 &gt;_ 0. More precisely,\nthe output of Gurvits algorithm is E ( Per ( _A_ )) such\nthat\n\nand this completes the proof.\n\n_|_ E ( Per ( _A_ )) _\u2212_ Per ( _A_ ) _| \u2264_ _\u03f5_ _||_ _A_ _||_ _n_ _._\n\nThe runtime of Gurvits is _O_ ( __ _n_ 2\n\nNow, we prove an analogue of the above the-\norem for estimating _|_ Per 2 ( _A_ ) _|_ from the output\nstatistics of linear optical circuits.\n**Theorem 2.** _Let A be an_ _n_ _\u00d7_ _n_ _matrix with en-_\n_tries in_ C _, and_ _\u03f5 &gt;_ 0 _._ _There is a linear opti-_\n_cal circuit_ _U_ _which, with_ _O_ (  1\n\n_\u03f5_ 2 ), and the above\ninequality holds with high probability (By Ho-\neffding\u2019s inequality [ 45 ]). The _O_ ( _n_ 2 ) part comes\nfrom the complexity of computing the Glynn co-\nefficients in Ryser\u2019s formula.\nWe prove the following.\n\n_\u03f5_ 2 ) _samples and with_\n_high probability outputs an estimate_ E ( _|_ Per 2 ( _A_ ) _|_ )\n_such that_\n\n**Theorem 1.** _For an_ _n_ _\u00d7_ _n_ _matrix_ _A_ _with entries_\n_in_ C _and_ _\u03f5 &gt;_ 0 _, Gurvits algorithm [_ _44_ _] outputs_\n_with high probability in_ _O_ ( __ _n_ 2\n\n\n E ( _|_ Per 2 ( _A_ ) _|_ ) _\u2212|_ Per 2 ( _A_ ) _|_\n\n _\u2264_ _\u03f5_ _||_ _A_ _||_ 2 _n_ _,_\n\n_\u03f5_ 2 ) _-time an estimate_\nE ( Per 2 ( _A_ )) _such that_\n\n _|_ E ( Per 2 ( _A_ )) _| \u2212|_ Per 2 ( _A_ ) _|_\n\n _\u2264_ _\u03f5_ (2 + _\u03f5_ ) _||_ _A_ _||_ 2 _n_ _._\n\n_Proof._ Embed _A_ onto a linear optical circuit _U_\nusing the unitary dilation theorem. From the re-\nsults of [ 52 ], by using Hoeffding\u2019s inequality [ 45 ],\nwe can with high confidence and with _O_ (  1\n\n_\u03f5_ 2 ) sam-\nples estimate the probability _p_ = _|_ Per 2 ( _A_ _s_ ) _|_ to\nwithin precision _\u03f5_ , where _A_ _s_ :=\n_A_\n\n_||_ _A_ _||_ _._ Therefore,\n\nwe obtain an estimate E ( _|_ Per 2 ( _A_ _s_ ) _|_ ) as follows\n\n_Proof._ Let E ( Per 2 ( _A_ )) := ( E ( Per ( _A_ )) 2 ,\nwhere E ( Per ( _A_ )) is the output of Gurvits\nalgorithm.\n_|_ E ( Per 2 ( _A_ )) _\u2212_ Per 2 ( _A_ ) _|_\n=\n_|_ E ( Per ( _A_ )) _\u2212_ Per ( _A_ ) _||_ E ( Per ( _A_ )) + Per ( _A_ ) _|_ _\u2264_\n_\u03f5_ _||_ _A_ _||_ _n_ ( _|_ E ( Per ( _A_ )) _|_ + _|_ Per ( _A_ ) _|_ ) _._\nUsing a reverse triangle inequality\n\n_\u2264_ _\u03f5_ _||_ _A_ _||_ _n_ _,_\n\n\n _|_ E ( Per ( _A_ )) _|\u2212|_ Per ( _A_ ) _|_\n\n _\u2264|_ E ( Per ( _A_ )) _\u2212_ Per ( _A_ ) _|_\n\n\n E ( _|_ Per 2 ( _A_ _s_ ) _|_ ) _\u2212|_ Per 2 ( _A_ _s_ ) _|_\n\n _\u2264_ _\u03f5._\n\nNoting that _|_ Per 2 ( _A_ _s_ ) _|_ = __ _|_ Per 2 ( _A_ ) _|_\n\nand consequently _|_ E ( Per ( _A_ )) _| \u2264|_ Per ( _A_ ) _|_ + _\u03f5_ _||_ _A_ _||_ _n_ _._\nPlugging this into the inequality of _|_ E ( Per 2 ( _A_ )) _\u2212_\nPer 2 ( _A_ ) _|_ gives\n\n_||_ _A_ _||_ 2 _n_ , then multiply-\ning both sides of the above inequality by _||_ _A_ _||_ 2 _n_ ,\nand defining E ( _|_ Per 2 ( _A_ ) _|_ ) := _||_ _A_ _||_ 2 _n_ E ( _|_ Per 2 ( _A_ _s_ ) _|_ )\ncompletes the proof.\n\n_|_ E ( Per 2 ( _A_ )) _\u2212_ Per 2 ( _A_ ) _| \u2264_ _\u03f5_ _||_ _A_ _||_ _n_ (2 _|_ Per ( _A_ ) _|_ + _\u03f5_ _||_ _A_ _||_ _n_ )\n\n_\u2264_ _\u03f5_ (2 + _\u03f5_ ) _||_ _A_ _||_ 2 _n_ _,_\n\n\n\n-----\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "2405.02267": {"__data__": {"id_": "2405.02267", "embedding": null, "metadata": {"title": "Structural Pruning of Pre-trained Language Models via Neural Architecture Search", "authors": "Aaron Klein, Jacek Golebiowski, Xingchen Ma, Valerio Perrone, Cedric Archambeau", "published": "2024-05-03", "filepath": "articles\\2405.02267v1.Structural_Pruning_of_Pre_trained_Language_Models_via_Neural_Architecture_Search.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "75\n\n0 _._ 80\n\n0 _._ 600\n\n0 _._ 800\n\n200 400 600 800 1000\n\n200 400 600 800 1000\n\n100 150 200 250 300 350 400\n\n100 150 200 250 300 350 400 450 500\n\nruntime (seconds)\n\nruntime (seconds)\n\nruntime (seconds)\n\nruntime (seconds)\n\n0 _._ 900 IMDB 1 _._ 00 SST2 SWAG\n\n0 _._ 900 QNLI\n\n\n|Col1|EHVI LS|\n|---|---|\n||MO-REA RS|\n|||\n|||\n|||\n|||\n|||\n|||\n\n\n0 _._ 700\n\n0 _._ 700\n\n200 400 600 800 1000\n\n1000 2000 3000 4000 5000\n\n2000 4000 6000 8000 10000\n\n250 500 750 1000 1250 1500 1750 2000\n\nruntime (seconds)\n\nruntime (seconds)\n\nruntime (seconds)\n\nruntime (seconds)\n\nFigure 11: Hypervolume of search methods for weight-sharing based NAS on BERT-base-cased (first two\nrows) and RoBERTa-base (last two rows).\n\nCOLA\n\nCOLA\n\n1.0\n\n1.0\n\n8bit\n\n8bit\n\n0.9\n\n0.9\n\n0.8\n\n0.8\n\n0.7\n\n0.7\n\n\n\n0.6\n\n0.6\n\n4bit\n\n4bit\n\nT4\nA10\nV100\n\n0.5\n\n0.5\n\n10 8 2 \u00d7 10 8 3 \u00d7 10 8 4 \u00d7 10 8\n\n10 0 10 1 10 2\n\nmemory footprint\n\nlatency (milli-seconds)\n\nFigure 12: Test error versus memory footprint (left) and latency (right) on 3 different GPU types for the\nPareto front found by our NAS strategy and the un-pruned network with 8bit and 4bit quantization.\n\n20\n\n\n\n-----\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "2405.02266": {"__data__": {"id_": "2405.02266", "embedding": null, "metadata": {"title": "On the test-time zero-shot generalization of vision-language models: Do we really need prompt learning?", "authors": "Maxime Zanella, Ismail Ben Ayed", "published": "2024-05-03", "filepath": "articles\\2405.02266v1.On_the_test_time_zero_shot_generalization_of_vision_language_models__Do_we_really_need_prompt_learning_.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "_l_ _\u2212_ 1\n\n20: **end while**\n\n21: **return** arg max _k_ **m** _t_ **t** _k_ _\u25b7_ return prediction based on the mode\n\n**Algorithm 3** Affinity measure based on predictions\n\n1: **function** A FFINITY ( **f** _p_ , **f** _q_ , ( **t** _k_ ) 1 _\u2264_ _k_ _\u2264_ _K_ , _\u03c4_ )\n\n2: **if** _p_ = _q_ **then**\n\n3: **return** 0\n\n4: **end if**\n\n5:\n_l_ _p,k_ _\u2190_ _\u03c4_ **f** __ _t_ _p_ **t** _k_ **** **;** _l_ _q,k_ __ _\u2190_ _\u03c4_ **f** _t_\n_q_ **t** _k_\n_\u2200_ _k_ _\u2208{_ 1 _, ..., K_ _}_\n_\u25b7_ similarity with class _k_\n\n6:\n_s_ _p,k_ _\u2190_\nexp _l_ _p,k_\nP _K_\n_j_ =1  exp _l_ _p,j_ **;** _s_ _q,k_ _\u2190_\nexp _l_ _q,k_\nP _K_\n_j_ =1  exp _l_ _q,j_ _\u2200_ _k_ _\u2208{_ 1 _, ..., K_ _}_\n_\u25b7_ Softmax operation\n\n7:\n_w_ _p,q_ _\u2190_ **s** _t_\n_p_ **s** _q_\n\n8: **return** _w_ _p,q_\n\n9: **end function**\n\n14\n\n\n\n-----\n\n\nTable 8. Details of Table 1 with averaged top-1 accuracy and standard deviation computed over 3 random seeds.\n\n**Method** **ImageNet** **-A** **-V2** **-R** **-Sketch** **Average**\n\nTPT \u2717\n68.94 54.63 63.41 77.04 47.97 62.40\n_\u00b1_ .06 _\u00b1_ .21 _\u00b1_ .12 _\u00b1_ .02 _\u00b1_ .05 _\u00b1_ .03\n\nMTA \u2713\n69.29 57.41 63.61 76.92 48.58 63.16\n_\u00b1_ .09 _\u00b1_ .15 _\u00b1_ .07 _\u00b1_ .13 _\u00b1_ .05 _\u00b1_ .07\n\nMTA + Ensemble \u2713\n70.08 58.06 64.24 78.33 49.61 64.06\n_\u00b1_ .03 _\u00b1_ .07 _\u00b1_ .09 _\u00b1_ .11 _\u00b1_ .06 _\u00b1_ .06\n\nTPT + CoOp \u2717\n73.61 57.85 66.69 77.99 49.59 65.14\n_\u00b1_ .17 _\u00b1_ .34 _\u00b1_ .25 _\u00b1_ .69 _\u00b1_ .34 _\u00b1_ .1\n\nMTA + CoOp \u2713\n73.99 59.29 66.97 78.2 49.96 65.68\n_\u00b1_ .18 _\u00b1_ .12 _\u00b1_ .25 _\u00b1_ .76 _\u00b1_ .46 _\u00b1_ .25\n\nTable 9. Details of Table 2 with averaged top-1 accuracy and standard deviation computed over 3 random seeds.\n\nMethod SUN397 Aircraft EuroSAT Cars Food101 Pets Flower102 Caltech101 DTD UCF101 Average\n\nTPT\n65.41 23.1 42.93 66.36 84.63 87.22 68.86 94.12 46.99 68.00 64.76\n_\u00b1_ .03 _\u00b1_ .39 _\u00b1_ .2 _\u00b1_ .31 _\u00b1_ .03 _\u00b1_ .19 _\u00b1_ .32 _\u00b1_ .21 _\u00b1_ .31 _\u00b1_ .22 _\u00b1_ .05\n\nMTA\n64.98 25.32 38.71 68.05 84.95 88.22 68.26 94.13 45.59 68.11 64.63\n_\u00b1_ 0 _\u00b1_ .25 _\u00b1_ .22 _\u00b1_ .16 _\u00b1_ .06 _\u00b1_ .07 _\u00b1_ .08 _\u00b1_ .02 _\u00b1_ .18 _\u00b1_ .11 _\u00b1_ .02\n\nMTA + E.\n66.67 25.2 45.36 68.47 85.00 88.24 68.06 94.21 45.9 68.69 65.58\n_\u00b1_ .05 _\u00b1_ .37 _\u00b1_ .16 _\u00b1_ .08 _\u00b1_ .03 _\u00b1_ .07 _\u00b1_ .2 _\u00b1_ .21 _\u00b1_ .09 _\u00b1_ .15 _\u00b1_ .05\n\nTable 10. Details of Table 3 with averaged top-1 accuracy and standard deviation computed over 3 random seeds.\n\n**Augmentation** **Method** **ImageNet** **-A** **-V2** **R** **-Sketch** **Average**\n\nRandomCrop\nTPT\n68.15 51.23 66.17 76.88 49.31 62.35\n_\u00b1_ .3 _\u00b1_ .31 _\u00b1_ .2 _\u00b1_ .2 _\u00b1_ .2 _\u00b1_ .05\n\nMTA\n69.11 55.27 65.71 77.48 50.23 63.56\n_\u00b1_ .4 _\u00b1_ .15 _\u00b1_ .4 _\u00b1_ .36 _\u00b1_ .4 _\u00b1_ .11\n\nDiffusion\nDiffTPT\n67.83 53.43 65.18 76.85 50.2 62.7\n_\u00b1_ .23 _\u00b1_ .64 _\u00b1_ .43 _\u00b1_ .11 _\u00b1_ .36 _\u00b1_ .19\n\nMTA\n69.18 54.5 64.81 76.82 51.09 63.28\n_\u00b1_ .4 _\u00b1_ .31 _\u00b1_ .1 _\u00b1_ .26 _\u00b1_ .4 _\u00b1_ .07\n\nTable 11. Details of Table 6 for _inlierness_ scores ablation study. (1) MeanShift (no _inlierness_ scores) (2) confidence thresh. (10%) (3)\n_Inlierness_ scores. I stands for ImageNet, A for ImageNet-A, V for ImageNet-V2, R for ImageNet-R and K for ImageNet-Sketch. Reported\nvalues are averaged top-1 accuracy and standard deviation computed over 3 random seeds.\n\nI A V R K SUN397 Aircraft EuroSAT Cars Food101 Pets Flower102 Caltech101 DTD UCF101 Average\n\n(1)\n66.1 48.05 60.29 67.69 40.59 63.74 25.11 24.72 66.53 83.12 85.24 66.69 91.52 44.35 65.16 59.93\n_\u00b1_ .03 _\u00b1_ .14 _\u00b1_ .23 _\u00b1_ .1 _\u00b1_ .05 _\u00b1_ .09 _\u00b1_ .1 _\u00b1_ .08 _\u00b1_ .2 _\u00b1_ .09 _\u00b1_ .22 _\u00b1_ .25 _\u00b1_ .11 _\u00b1_ .24 _\u00b1_ .05 _\u00b1_ .07\n\n(2)\n68.26 60.66 63.3 76.14 47.59 63.56 24.52 36.13 67.59 83.39 85.83 66.51 92.69 45.45 67.41 63.27\n_\u00b1_ .07 _\u00b1_ .19 _\u00b1_ .13 _\u00b1_ .08 _\u00b1_ .05 _\u00b1_ .11 _\u00b1_ .24 _\u00b1_ .04 _\u00b1_ .09 _\u00b1_ .14 _\u00b1_ .32 _\u00b1_ .42 _\u00b1_ .1 _\u00b1_ .1 _\u00b1_ .39 _\u00b1_ .04\n\n(3)\n69.29 57.41 63.61 76.92 48.58 64.98 25.32 38.71 68.05 84.95 88.22 68.26 94.13 45.59 68.11 64.14\n_\u00b1_ .09 _\u00b1_ .15 _\u00b1_ .07 _\u00b1_ .13 _\u00b1_ .05 _\u00b1_ 0 _\u00b1_ .25 _\u00b1_ .22 _\u00b1_ .16 _\u00b1_ .06 _\u00b1_ .07 _\u00b1_ .08 _\u00b1_ .02 _\u00b1_ .18 _\u00b1_ .11 _\u00b1_ .01\n\n15\n\n\n\n-----\n\n\nImageNet SUN397 Aircraft\n\n90 EuroSAT\n\n\n|Col1|Col2|Col3|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n|||||||\n|||||||\n|||||||\n|||||||\n||||||CoOp (M=16) CoOp (M=16) + MTA|\n||||||CoOp (M=16) + TPT|\n\n|Col1|Col2|Col3|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n|||||||\n|||||||\n|||||||\n|||||||\n||||||CoOp (M=16) CoOp (M=16) + MTA|\n||||||CoOp (M=16) + TPT|\n\n|Col1|Col2|Col3|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n|||||||\n|||||||\n|||||||\n|||||||\n||||||CoOp (M=16) CoOp (M=16) + MTA|\n||||||CoOp (M=16) + TPT|\n\n|Col1|Col2|Col3|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n|||||||\n|||||||\n|||||||\n||||||CoOp (M=16) CoOp (M=16) + MTA|\n||||||CoOp (M=16) + TPT|\n\n\n1 2 4 8 16\n\n1 2 4 8 16\n\n1 2 4 8 16\n\n1 2 4 8 16\n\nNumber of shots\n\nNumber of shots\n\nNumber of shots\n\nNumber of shots\n\nCars Food101 Pets Caltech101\n\n\n|Col1|Col2|Col3|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n|||||||\n|||||||\n|||||||\n||||||CoOp (M=16) CoOp (M=16) + MTA CoOp (M=16) + TPT|\n|||||||\n|||||||\n\n|Col1|Col2|Col3|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n|||||||\n|||||||\n|||||||\n||||||CoOp (M=16) CoOp (M=16) + MTA CoOp (M=16) + TPT|\n|||||||\n|||||||\n\n|Col1|Col2|Col3|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n|||||||\n|||||||\n|||||||\n|||||||\n|||||||\n||||||CoOp (M=16)|\n||||||CoOp (M=16) + MTA CoOp (M=16) + TPT|\n|||||||\n\n|Col1|Col2|Col3|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n|||||||\n|||||||\n|||||||\n||||||CoOp (M=16) CoOp (M=16) + MTA CoOp (M=16) + TPT|\n|||||||\n|||||||\n\n\n86\n\n1 2 4 8 16\n\n1 2 4 8 16\n\n1 2 4 8 16\n\n1 2 4 8 16\n\nNumber of shots\n\nNumber of shots\n\nNumber of shots\n\nNumber of shots\n\nUCF101 Flower102 DTD\nAverage\n\n\n|Col1|Col2|Col3|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n|||||||\n|||||||\n||||||CoOp (M=16)|\n||||||CoOp (M=16) + MTA CoOp (M=16) + TPT|\n\n|Col1|Col2|Col3|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n|||||||\n|||||||\n|||||||\n||||||CoOp (M=16)|\n||||||CoOp (M=16) + MTA CoOp (M=16) + TPT|\n\n|Col1|Col2|Col3|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n|||||||\n|||||||\n|||||||\n||||||CoOp (M=16)|\n||||||CoOp (M=16) + MTA CoOp (M=16) + TPT|\n\n|Col1|Col2|Col3|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n|||||||\n|||||||\n|||||||\n||||||CoOp (M=16)|\n||||||CoOp (M=16) + MTA CoOp (M=16) + TPT|\n\n\n65.0\n\n70\n\n1 2 4 8 16\n\n1 2 4 8 16\n\n1 2 4 8 16\n\n1 2 4 8 16\n\nNumber of shots\n\nNumber of shots\n\nNumber of shots\n\nNumber of shots\n\nFigure 5. Additional results for Figure 3 with M=16 tokens for the CoOp pretrained prompts.\n\n16\n\n\n\n-----\n\n\nTable 12. The 80 handcrafted prompts used for majority vote.\n\n\u201d a photo of a [].\u201d, \u201d a bad photo of a [].\u201d, \u201d a photo of many [].\u201d, \u201d a sculpture of a [].\u201d,\n\u201d a photo of the hard to see [].\u201d, \u201d a low resolution photo of the [].\u201d, \u201d a rendering of a [].\u201d,\n\u201d graffiti of a [].\u201d, \u201d a bad photo of the [].\u201d, \u201d a cropped photo of the [].\u201d,, \u201d a tattoo of a [].\u201d,\n\u201d the embroidered [].\u201d, \u201d a photo of a hard to see [].\u201d, \u201d a bright photo of a [].\u201d,\n\u201d a photo of a clean [].\u201d, \u201d a photo of a dirty [].\u201d, \u201d a dark photo of the [].\u201d,\n\u201d a drawing of a [].\u201d, \u201d a photo of my [].\u201d, \u201d the plastic [].\u201d, \u201d a photo of the cool [].\u201d,\n\u201d a close-up photo of a [].\u201d, \u201d a black and white photo of the [].\u201d, \u201d a painting of the [].\u201d,\n\u201d a painting of a [].\u201d, \u201d a pixelated photo of the [].\u201d, \u201d a sculpture of the [].\u201d,\n\u201d a bright photo of the [].\u201d, \u201d a cropped photo of a [].\u201d, \u201d a plastic [].\u201d,\n\u201d a photo of the dirty [].\u201d, \u201d a jpeg corrupted photo of a [].\u201d, \u201d a blurry photo of the [].\u201d,\n\u201d a photo of the [].\u201d, \u201d a good photo of the [].\u201d, \u201d a rendering of the [].\u201d,\n\u201d a [] in a video game .\u201d, \u201d a photo of one [].\u201d, \u201d a doodle of a [].\u201d,\n\u201d a close-up photo of the [].\u201d, \u201d the origami [].\u201d, \u201d the [] in a video game .\u201d,\n\u201d a sketch of a [].\u201d, \u201d a doodle of the [].\u201d, \u201d a origami [].\u201d, \u201d a low resolution photo of a [].\u201d,\n\u201d the toy [].\u201d, \u201d a rendition of the [].\u201d, \u201d a photo of the clean [].\u201d, \u201d a photo of a large [].\u201d,\n\u201d a rendition of a [].\u201d, \u201d a photo of a nice [].\u201d, \u201d a photo of a weird [].\u201d,\n\u201d a blurry photo of a [].\u201d, \u201d a cartoon [].\u201d, \u201d art of a [].\u201d, \u201d a sketch of the [].\u201d,\n\u201d a embroidered [].\u201d, \u201d a pixelated photo of a [].\u201d, \u201d itap of the [].\u201d,\n\u201d a jpeg corrupted photo of the [].\u201d, \u201d a good photo of a [].\u201d, \u201d a plushie [].\u201d,\n\u201d a photo of the nice [].\u201d, \u201d a photo of the small [].\u201d, \u201d a photo of the weird [].\u201d,\n\u201d the cartoon [].\u201d, \u201d art of the [].\u201d, \u201d a drawing of the [].\u201d, \u201d a photo of the large [].\u201d,\n\u201d a black and white photo of a [].\u201d, \u201d the plushie [].\u201d, \u201d a dark photo of a [].\u201d, \u201d itap of a [].\u201d,\n\u201d graffiti of the [].\u201d, \u201d a toy [].\u201d, \u201d itap of my [].\u201d, \u201d a photo of a cool [].\u201d,\n\u201d a photo of a small [].\u201d, \u201d a tattoo of the [].\u201d\n\n17\n\n\n\n-----\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}}}